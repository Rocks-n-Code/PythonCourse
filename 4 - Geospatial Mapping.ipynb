{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "CrudeAudacity_Geospatial_Mapping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocks-n-Code/PythonCourse/blob/master/4%20-%20Geospatial%20Mapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG8HVu_fRSiX"
      },
      "source": [
        "<font size=20, color=\"#00b140\"><b>Making Maps in Python</b></font>\n",
        "<br>\n",
        "<font color=\"#00b140\"><i><b>An Overview</b></i></font>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "This notebook will take you through python code very commonly used to import, sort, and visualize some data, in this case a spreadsheet of USGS core data. We will use `pandas`, a fast, powerful, flexible, and easy-to-use data analysis and manipulation tool, and several packages for geospatial map-making, including `geopandas`, `folium`, and `plotly`.\n",
        "\n",
        "By completing this notebook, you will be able to:\n",
        "- See how easy it is to interact with a large dataset that would be cumbersome to handle in Excel (16,000 rows with 25 rows)\n",
        "- Slice, group, and combine data and perform basic data exploration and visualization\n",
        "- Make some basic and some fancy maps in python! \n",
        "\n",
        "Open this notebook in Colab by clicking this link! [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1grBYTcJwY9oj4DgnQDuUJVkeHLeeFM-b?usp=sharing)\n",
        "\n",
        "---------------------\n",
        "\n",
        "This notebook created by:\n",
        "\n",
        "**Zane Jobe** \n",
        "\n",
        "[![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/ZaneJobe.svg?style=social&label=Follow%20%40ZaneJobe)](https://twitter.com/ZaneJobe)\n",
        "on Twitter or email me at zanejobe@mines.edu\n",
        "\n",
        "Zane is an Associate Research Professor in the Department of Geology and Geological Engineering, Colorado School of Mines, and serves as the Director of the [CoRE research group](https://core.mines.edu/) for sedimentary geology and the Leader of the [Data Science: Earth Resources](https://online.mines.edu/er/) online graduate certificate at Mines. \n",
        "\n",
        "Prior to Mines, Zane spent 6 years in the Clastics Research Team at Shell Oil Company. His research interests aim to better understand the stratigraphic architecture, scaling relationships, and sediment budgets for channelized depositional systems, with an emphasis on submarine environments. He also enjoys cycling and thinks that copious amounts of yard work can be cathartic. Zane received a B.S. in Geology from the University of Texas at Arlington in 2004, and a Ph.D. in Geology from Stanford University in 2010 (advisor - Don Lowe).\n",
        "\n",
        "-------------------\n",
        "# OK, let's do some coding!\n",
        "## First, let's import some packages\n",
        "In any python project, you need to install and import the packages you will be using. This is pretty easy in Colab or Jupyter using using `pip` and `import`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caob4Ux1syVZ"
      },
      "source": [
        "# install stuff\n",
        "!pip install geopandas\n",
        "!pip install earthpy\n",
        "!pip install plotly==4.10.0 # needs to be this latest version (Sept 2020)\n",
        "\n",
        "# import stuff\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "import geopandas as gpd\n",
        "import earthpy as et\n",
        "\n",
        "import folium\n",
        "\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEoyerAOPjDj"
      },
      "source": [
        "## Import some data\n",
        "We will use a csv file that has lists all the cores in the USGS Core Research Center in Lakewood, CO. I just downloaded it directly from the website and made no changes to it. That's the whole point of all this, which is to work with data you can easily obtain and not spend time manually changing things in Excel. \n",
        "\n",
        "You don't need to do this, but if you want to recreate this dataset, you can download this exact spreadsheet from the [USGS CRC](https://my.usgs.gov/crcwc/). Just click search, don't type anything into the boxes. You should get 16,531 rows (as of Feb 2020), which you can export as a CSV at the bottom of the page. You could do the same things for cuttings by clicking on the cuttings tab (there are 53,456 rows in the cuttings database), but we will just stick with cores for now - 16,000 rows is plenty of data for our first foray into python!\n",
        "\n",
        "If the code to import the data does not work, you can go to [this csv](https://docs.google.com/spreadsheets/d/1fX8ZyF2Pmx7apcBftvWVVOUlPTCRl014cIASIowAVNE/edit?usp=sharing) in Google Drive - open it in Google Sheets, and then click 'Share' in the upper right hand corner. Copy the link, and then paste it below, replacing the `view?usp=sharing` with `export?format=csv`.\n",
        "\n",
        "BTW - if instead you go to the file straight in Google Drive, and copy the link from there rather than inside of Google Sheets, you need to do the import a slightly different way (described in this [stackoverflow post](https://stackoverflow.com/questions/56611698/pandas-how-to-read-csv-file-from-google-drive-public)). Why it is different in Sheets vs, Drive, I do not know..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK41qsdvO-A2"
      },
      "source": [
        "# import data using pandas\n",
        "df = pd.read_csv('https://docs.google.com/spreadsheets/d/1fX8ZyF2Pmx7apcBftvWVVOUlPTCRl014cIASIowAVNE/export?format=csv')\n",
        "\n",
        "df.head(2) # show the first two lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVrzYlpkZYWo"
      },
      "source": [
        "## Check out what is in the `DataFrame` we just made"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amOadD_6ZTgw"
      },
      "source": [
        "df.info() # this lists all of the column names and their attributes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0dJLUCIu3Qb"
      },
      "source": [
        "# now let's make a thickness value from the Depth columns, and then add it to the DataFrame\n",
        "\n",
        "th=df['Max Depth']-df['Min Depth'] # make the variable\n",
        "df['Thickness']=th                 # assign it to a new column in dataframe called thickness\n",
        "df.Thickness.describe()            # get some stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zsvTAd7vNPb"
      },
      "source": [
        "A median of 41 feet per well seems ok, but the mean is 126, so the distribution is extremely log-normal. Notice the max and min are obviously errors in the database. We won't worry about that for now, as we want to check out the bulk statistics of the database. But good to know there may be a few weird values that you would want to filter out. \n",
        "\n",
        "Also, note that there are a few thickness values missing, as the dataframe is 16531 rows and the thickness only has 16485 rows (meaning some rows don't have depth values)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU0o4BOgvkmo"
      },
      "source": [
        "original_length = len(df)\n",
        "\n",
        "df = df[df.Thickness>0]            # get rid of negative values\n",
        "df = df[df.Thickness<1000]         # get rid of huge values\n",
        "\n",
        "dropped = original_length - len(df)\n",
        "\n",
        "print(str(dropped)+' values dropped out of '+str(original_length)+' values')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgUCuzcS4Moq"
      },
      "source": [
        "## Now let's make some simple plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTc2CBMb76fj"
      },
      "source": [
        "df.hist('Thickness');              # histogram of thickness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aXZxpp57r8D"
      },
      "source": [
        "sns.kdeplot(df.Thickness, shade=True); \n",
        "# distribution of thickness using a kernel density function - looks nicer, eh?!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxqhOEDz8nBV"
      },
      "source": [
        "df.plot(x='Longitude', y='Latitude')\n",
        "plt.title('Eww that\\'s gross');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n45Zsay49Q5t"
      },
      "source": [
        "plt.scatter(df.Longitude,df.Latitude, s=0.5);\n",
        "# slightly better - can you see the Alaska cores?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhpT9NDQ8w5-"
      },
      "source": [
        "# Let's clip Alaska out of the plot\n",
        "# and make a bubble plot of core thickness\n",
        "\n",
        "plt.scatter(df.Longitude,df.Latitude, s=df.Thickness/50)\n",
        "plt.xlim([-120, -90])\n",
        "plt.ylim([30, 50]);\n",
        "\n",
        "# Can you see the Rockies? This is starting to look like the US, \n",
        "# but we can do so much better, as you will see below"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZapLlF1l9l6J"
      },
      "source": [
        "### But before we go onto making fancier maps, let's make some bar charts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7EW__JU38JP"
      },
      "source": [
        "fm_counts=df['Formation'].value_counts() # get value counts of all the formations\n",
        "\n",
        "sns.barplot(y=fm_counts.index[0:20], \n",
        "            x=fm_counts.values[0:20])    # plot it\n",
        "plt.title('Top 20 Formations with the most cores');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tF-XE9R4ST6"
      },
      "source": [
        "# Show what types of data are in Colorado\n",
        "co=df.loc[df['State']=='CO']\n",
        "co_counts=co['Type'].value_counts()\n",
        "sns.barplot(y=co_counts.index, x=co_counts.values)\n",
        "plt.title('Types of core data in Colorado');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqL6QH3Q8XLM"
      },
      "source": [
        "## Now you try to make a simple plot\n",
        "Pick anbything! Perhaps a KDE of core thickness from a particular state? Howver, don't fool with lat-long for now, we will spend plenty of time on that later..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdaEOeq38TT2"
      },
      "source": [
        "# your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39vOXezsyCFN"
      },
      "source": [
        "# Now, let's only look at Wyoming and Colorado cores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzspLQhZwikA"
      },
      "source": [
        "cowy=df[df['State'].isin(['CO','WY'])] # Try doing that in Excel...\n",
        "\n",
        "# Now let's view the number of cores grouped by Formation and State\n",
        "fm_state=cowy.groupby(['Formation','State']).size()\n",
        "fm_state=fm_state.sort_values(ascending=False) # sort the values in descending order (i.e., with the largest values at the top)\n",
        "print(fm_state[0:25])                          # only show the top 25 values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikzw2AdT3DVm"
      },
      "source": [
        "# Print some results from one Formation\n",
        "Fm_of_interest=cowy[cowy['Formation']=='GREEN RIVER']  # pull only one formation out\n",
        "print('There are',len(Fm_of_interest),'green river cores')\n",
        "print('Top five wells are:')\n",
        "print(Fm_of_interest['Well Name'].value_counts()[0:5]) # show the number of cores from each well name (display only the top five)\n",
        "\n",
        "slab=Fm_of_interest[Fm_of_interest['Type'].isin(['SLABBED'])] # find only slabbed cores (i.e., not whole core or butts)\n",
        "print('') # white space\n",
        "print('There are',len(slab),'slabbed green river cores') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZg0cc8m4Zb-"
      },
      "source": [
        "# Now look at Fields in Natrona County, WY\n",
        "wy=df[df['State'].isin(['WY'])]            # only Wyoming\n",
        "natrona=wy[wy['County'].isin(['NATRONA'])] # only Natrona County\n",
        "natrona_fields=natrona.groupby('Field').size()\n",
        "natrona_fields.sort_values(ascending=False)[0:10] # top 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwP_303h2vvk"
      },
      "source": [
        "## Now you try a groupby of some of the other columns:\n",
        "Maybe By `Age` and `Formation`? Or `State` and `County`? Choose any of the column names, but consider whether they are useful for grouping. For example, depth probably isn't useful here, as each core will have a slightly different depth values, so you would end up with thousands of groups. \n",
        "\n",
        "You can use the `cowy` variable or make a new one with a different state..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt16RACR2wlv"
      },
      "source": [
        "# your code goes here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L-xkWE6OfLP"
      },
      "source": [
        "# Basic maps using geopandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPQOPoGu_8-1"
      },
      "source": [
        "# get basic geopandas data\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "\n",
        "'''\n",
        "get county data for the US from this website\n",
        "https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
        "\n",
        "We will do this with Earthpy, which takes the zip file, stores it in Colab, and then unzips it and feeds it to geopandas\n",
        "'''\n",
        "\n",
        "counties = gpd.read_file(\n",
        "    et.data.get_data(\n",
        "        url=\n",
        "        'https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_county_500k.zip'\n",
        "        )\n",
        "    )\n",
        "\n",
        "'''\n",
        "Now Let's get some custom data from the EIA\n",
        "I got the data from this website https://www.eia.gov/maps/maps.htm, and here is a summary map: https://www.eia.gov/maps/images/shale_gas_lower48.jpg\n",
        "'''\n",
        "\n",
        "plays = gpd.read_file(\n",
        "    et.data.get_data(\n",
        "        url=\n",
        "        'https://www.eia.gov/maps/map_data/TightOil_ShaleGas_Plays_Lower48_EIA.zip'\n",
        "        )\n",
        "    )\n",
        "\n",
        "basins = gpd.read_file(\n",
        "    et.data.get_data(\n",
        "        url=\n",
        "        'https://www.eia.gov/maps/map_data/SedimentaryBasins_US_EIA.zip'\n",
        "        )\n",
        "    )\n",
        "\n",
        "'''\n",
        "get NaturalEarthdata\n",
        "the links below copied from https://github.com/nvkelso/natural-earth-vector/tree/master/geojson\n",
        "but you can also go to this site https://www.naturalearthdata.com/downloads/\n",
        "\n",
        "For some weird reason, Colab doesnt like Earthpy .zip files for these (see below for an example), so \n",
        "we will be using the geojson files directly from Github instead...\n",
        "'''\n",
        "coastlines = gpd.read_file('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_50m_coastline.geojson')\n",
        "\n",
        "countries = gpd.read_file('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_50m_admin_0_boundary_lines_land.geojson')\n",
        "\n",
        "rivers = gpd.read_file('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_10m_rivers_lake_centerlines.geojson')\n",
        "\n",
        "states = gpd.read_file('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_110m_admin_1_states_provinces.geojson')\n",
        "\n",
        "cities = gpd.read_file('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_10m_populated_places.geojson')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0dILPA-_AEs"
      },
      "source": [
        "For any of these data, you could also:\n",
        "\n",
        "- Download the files (don't unzip them)\n",
        "- click on the little folder icon on the left-hand sidebar\n",
        "- click the little up-arrow button, and select the zip file and upload them\n",
        "- then right-click on that file and copy the path and use it to read directly into geopandas using gpd.read_file('filename.shp')\n",
        "\n",
        "## Let's take a look at some of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o75cawFaN7pT"
      },
      "source": [
        "basins.head(3) # what does basins look like?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHD5y3WZ_9BN"
      },
      "source": [
        "# Let's make a simple figure\n",
        "\n",
        "fig, ax = plt.subplots(figsize=[15,15])\n",
        "world.boundary.plot(ax=ax,color='k') #the boundary method only plots the outlines\n",
        "rivers.plot(ax=ax,color='b',linewidth=0.5)\n",
        "ax.set_aspect('equal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4Nk8KbD_9Ds"
      },
      "source": [
        "world.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BTQwSy1SmHC"
      },
      "source": [
        "It would be nice to be able to label these countries or cities. See if you can figure out how to do that (here is a [hint](https://github.com/shotleft/how-to-python/blob/master/How%20it%20works%20-%20labelling%20districts%20in%20GeoPandas.ipynb)). \n",
        "\n",
        "First, subset the geodataframe so that it is just one continent, and then plot only that continent and its country labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvo7flRLeUb3"
      },
      "source": [
        "world.continent.unique() # what continents do we have?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB6gPG3v_9GJ"
      },
      "source": [
        "#only south america\n",
        "south_america = world[world.continent=='South America']\n",
        "africa = world[world.continent=='Africa']\n",
        "\n",
        "#plot\n",
        "fig, axs = plt.subplots(1,2,figsize=[10,5])\n",
        "south_america.plot(ax=axs[0],color='whitesmoke', edgecolor='k',linewidth=0.5)\n",
        "africa.plot(ax=axs[1],color='whitesmoke', edgecolor='k',linewidth=0.5)\n",
        "\n",
        "#labels\n",
        "south_america.apply(lambda x: axs[0].annotate(s=x['name'], xy=x.geometry.centroid.coords[0], ha='center',fontsize=8,color='black'),axis=1);\n",
        "\n",
        "# can also loop it like this:\n",
        "for x, y, label in zip(africa.centroid.x, \n",
        "                       africa.centroid.y, \n",
        "                       africa.name):\n",
        "    axs[1].text(x, y, label, fontsize = 6, color='k', ha='center')\n",
        "\n",
        "for ax in axs: ax.set_aspect('equal')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqgJjTRrC7Oh"
      },
      "source": [
        "# Now you try!\n",
        "\n",
        "# your code here\n",
        "# your code here\n",
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfynN8fga9kE"
      },
      "source": [
        "### Now let's look at EIA 'oil shale basins':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se26y67w_9PN"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=[15,15])\n",
        "\n",
        "basins.plot(ax=ax,facecolor='xkcd:blue', alpha=0.2, edgecolor='none') # shade\n",
        "basins.plot(ax=ax,facecolor='none', edgecolor='xkcd:blue', linewidth=2) # outlines\n",
        "states.plot(ax=ax,facecolor='none',edgecolor='k',linewidth=1)\n",
        "\n",
        "ax.scatter(df.Longitude, df.Latitude, s=1, facecolors='none', edgecolors='xkcd:orange')\n",
        "\n",
        "basins.apply(lambda x: ax.annotate(s=x['NAME'], xy=x.geometry.centroid.coords[0], ha='center',fontsize=8,color='black'),axis=1);\n",
        "\n",
        "ax.set_xlim([-130,-65])\n",
        "ax.set_ylim([24,50])\n",
        "ax.set_aspect('equal');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mZTfdk6R3bq"
      },
      "source": [
        "Looks a bit stretched - this has to do with the coordinate reference system - these are in a geographic coordinate system (WGS84), and we are used to looking at things in Mercator projection are projected in WGS84, but we are used to looking at things in Spherical Mercator, which is a projected coordinate system. Here is a [good intro](https://jcutrer.com/python/learn-geopandas-plotting-usmaps) to this issue. \n",
        "\n",
        "Let's take a look at the CRS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34sVfT1oSagU"
      },
      "source": [
        "basins.crs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcKVQ6mRS4_i"
      },
      "source": [
        "# Let's also take our original dataframe and make it a geopandas\n",
        "# We will also reproject all the data in there to be in Mercator\n",
        "df_geo = gpd.GeoDataFrame(df, crs='EPSG:4326', geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\n",
        "\n",
        "albers_equal_area = 'EPSG:2163'\n",
        "google_maps = 'EPSG:3857'\n",
        "\n",
        "df_geo = df_geo.to_crs(albers_equal_area)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNZU6B_qNXcU"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=[15,15])\n",
        "\n",
        "basins_proj = basins.to_crs(albers_equal_area)\n",
        "states_proj = states.to_crs(albers_equal_area)\n",
        "\n",
        "# only the Lower 48 one-liner\n",
        "states_proj.drop(states_proj[states_proj.name.isin(['Alaska','Hawaii'])].index, inplace=True) \n",
        "\n",
        "basins_proj.plot(ax=ax,facecolor='xkcd:blue green', alpha=0.2, edgecolor='none') # shade\n",
        "basins_proj.plot(ax=ax,facecolor='none', edgecolor='xkcd:blue green') # outlines\n",
        "states_proj.plot(ax=ax,facecolor='none',edgecolor='k',linewidth=1)\n",
        "\n",
        "df_geo.plot(ax=ax,color='xkcd:orange',markersize=1)\n",
        "\n",
        "basins_proj.apply(lambda x: ax.annotate(s=x['NAME'], xy=x.geometry.centroid.coords[0], ha='center',fontsize=8,color='black'),axis=1);\n",
        "\n",
        "xlim = ([states_proj.total_bounds[0],  states_proj.total_bounds[2]])\n",
        "ylim = ([states_proj.total_bounds[1],  states_proj.total_bounds[3]])\n",
        "\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "ax.set_aspect('equal');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YnvkbaYUFxw"
      },
      "source": [
        "# compare two projections\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=[20,10])\n",
        "\n",
        "# EQUAL AREA\n",
        "basins_proj.plot(ax=axs[0],facecolor='xkcd:blue green', alpha=0.2, edgecolor='none') # shade\n",
        "basins_proj.plot(ax=axs[0],facecolor='none', edgecolor='xkcd:blue green') # outlines\n",
        "states_proj.plot(ax=axs[0],facecolor='none',edgecolor='k',linewidth=1)\n",
        "df_geo.plot(ax=axs[0],color='xkcd:orange',markersize=1)\n",
        "basins_proj.apply(lambda x: axs[0].annotate(s=x['NAME'], xy=x.geometry.centroid.coords[0], ha='center',fontsize=8,color='black'),axis=1);\n",
        "xlim = ([states_proj.total_bounds[0],  states_proj.total_bounds[2]]); ylim = ([states_proj.total_bounds[1],  states_proj.total_bounds[3]])\n",
        "axs[0].set_xlim(xlim); axs[0].set_ylim(ylim); axs[0].set_aspect('equal');\n",
        "\n",
        "# GOOGLE MAPS Psuedo Mercator\n",
        "basins_proj = basins.to_crs(google_maps)\n",
        "states_proj = states_proj.to_crs(google_maps)\n",
        "df_geo = df_geo.to_crs(google_maps)\n",
        "\n",
        "basins_proj.plot(ax=axs[1],facecolor='xkcd:blue green', alpha=0.2, edgecolor='none') # shade\n",
        "basins_proj.plot(ax=axs[1],facecolor='none', edgecolor='xkcd:blue green') # outlines\n",
        "states_proj.plot(ax=axs[1],facecolor='none',edgecolor='k',linewidth=1)\n",
        "df_geo.plot(ax=axs[1],color='xkcd:orange',markersize=1)\n",
        "basins_proj.apply(lambda x: axs[1].annotate(s=x['NAME'], xy=x.geometry.centroid.coords[0], ha='center',fontsize=8,color='black'),axis=1);\n",
        "xlim = ([states_proj.total_bounds[0],  states_proj.total_bounds[2]]); ylim = ([states_proj.total_bounds[1],  states_proj.total_bounds[3]])\n",
        "axs[1].set_xlim(xlim); axs[1].set_ylim(ylim); axs[1].set_aspect('equal');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZX3bg1e_9Rf"
      },
      "source": [
        "# now just the Powder River Basin\n",
        "cities_sub = cities.to_crs(google_maps)[cities.ADM1NAME=='Wyoming']\n",
        "df_geo_sub = df_geo[df_geo.State=='WY']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=[10,10])\n",
        "\n",
        "basins_proj[basins_proj.NAME=='POWDER RIVER'].plot(ax=ax,facecolor='xkcd:blue green', alpha=0.2, edgecolor='none') # shade\n",
        "basins_proj[basins_proj.NAME=='POWDER RIVER'].plot(ax=ax,facecolor='none', edgecolor='xkcd:blue green') # outlines\n",
        "states_proj[states_proj.name=='Wyoming'].plot(ax=ax,facecolor='none',edgecolor='k',linewidth=2)\n",
        "states_proj[states_proj.name=='Montana'].plot(ax=ax,facecolor='none',edgecolor='k',linewidth=2)\n",
        "\n",
        "cities_sub.plot(ax=ax,color='k',markersize=20)\n",
        "\n",
        "df_geo_sub[df_geo_sub.Formation=='PARKMAN'].plot(ax=ax,color='xkcd:orange',markersize=5)\n",
        "\n",
        "cities_sub.apply(lambda x: ax.annotate(s=x['NAME'], xy=x.geometry.centroid.coords[0],ha='right',fontsize=8,color='black'),axis=1);\n",
        "\n",
        "ax.set_aspect('equal')\n",
        "plt.tight_layout();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSLTi0v7Qqyo"
      },
      "source": [
        "### Your turn!\n",
        "\n",
        "Pick another basin and formation, and make another map!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odHMPSQBQoIx"
      },
      "source": [
        "### your code goes here\n",
        "\n",
        "# figure out a basin and formation using pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOVozvVcRnDY"
      },
      "source": [
        "### your code goes here\n",
        "\n",
        "# Now plot it using geopandas!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueXbBps7P3lo"
      },
      "source": [
        "## Folium web-mapping\n",
        "Folium is a pretty cool package in python that allows you to make interactive, zoomable maps using a Java package called leaflet. We will only scratch the surface of the [capabilities of Folium](https://python-visualization.github.io/folium/quickstart.html) - you can embed these maps on a website, and make all kinds of cool, interactive plots. \n",
        "\n",
        "These types of maps are super useful when you need to re-plot the same map over and over, for example, to update a website for weekly rainfall data, or highlight counties that have active wells drilling, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eNAGcPtNnbX"
      },
      "source": [
        "# define a dataset to map\n",
        "formation_to_map = df[df.Formation=='NIOBRARA'] # subset the original dataframe\n",
        "\n",
        "formation_to_map = formation_to_map.dropna(subset=['Latitude']) # get rid of wells with no location information\n",
        "\n",
        "# now create a map\n",
        "m = folium.Map(\n",
        "    location=[42, -105],\n",
        "    tiles='Stamen Terrain',\n",
        "    zoom_start=6\n",
        ")\n",
        "\n",
        "# and add stuff to that map\n",
        "for row in formation_to_map.iterrows():\n",
        "  row_values = row[1]\n",
        "  location = [row_values['Latitude'], row_values['Longitude']]\n",
        "  popup = row_values['Well Name']\n",
        "  folium.Marker(location = location, popup = popup).add_to(m)\n",
        "\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPeXhMtQT26a"
      },
      "source": [
        "# get some info about a particular well\n",
        "\n",
        "# click on a well and copy the well name, then paste it below \n",
        "name = '2 BOXELDER FARMS'\n",
        "\n",
        "df[df['Well Name']==name]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2fR10cuTW3-"
      },
      "source": [
        "Now let's try another formation, and we will use the OpenStreetMap tiles this time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjcozJY4Sz6D"
      },
      "source": [
        "formation_to_map = df[df.Formation=='PARKMAN'] # subset the original dataframe\n",
        "\n",
        "formation_to_map = formation_to_map.dropna(subset=['Latitude']) # get rid of wells with no location information\n",
        "\n",
        "# now create a map\n",
        "m = folium.Map(\n",
        "    location=[45, -105],\n",
        "    tiles='OpenStreetMap',\n",
        "    zoom_start=6\n",
        ")\n",
        "\n",
        "# and add stuff to that map\n",
        "for row in formation_to_map.iterrows():\n",
        "  row_values = row[1]\n",
        "  location = [row_values['Latitude'], row_values['Longitude']]\n",
        "  popup = row_values['Well Name']\n",
        "  folium.Marker(location = location, popup = popup).add_to(m)\n",
        "\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN1b54SnfsEK"
      },
      "source": [
        "### Another way, using geojson format (which we won't do today)\n",
        "In addition to pandas dataframe, another common way to store this type of data is in a geojson file. More on that format at [geojson.org](https://geojson.org). An example of creating a geojson file from a pandas DataFrame is shown in a nice notebook [here](https://github.com/gboeing/urban-data-science/blob/master/17-Leaflet-Web-Mapping/leaflet-simple-demo/pandas-to-geojson.ipynb). Feel free to test that out! We won't get into those details now, but now you have the background to be able to play around with `folium` or `Basemap` or `ipyleaflet` or some of the other web-mapping programs! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcxpOVn_fuiS"
      },
      "source": [
        "## Plotly\n",
        "\n",
        "Plotly is pretty sweet - it's even easier than folium, in my opinion. Beware, however, that plotly is a business, and they make money by getting you to sign up for their API and dashboard. So, it's really only partially open-source...\n",
        "\n",
        "Brendon Hall has a nice plotly notebook that he summarized in [this LinkedIn post](https://www.linkedin.com/pulse/interactive-well-maps-python-brendon-hall). Check that out, as well as the myriad of plotly tutorials online. \n",
        "\n",
        "### Let's look at the USGS website\n",
        "Go check out the [Map based search](https://my.usgs.gov/crcwc/map) at the USGS CRC. Are you ready to recreate that map (and actually make it better) in about ten lines of code? \n",
        "\n",
        "### Let's make a quick plotly map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba3UzUjKPzEq"
      },
      "source": [
        "df_sub = df[df.State=='WY']\n",
        "df_sub = df_sub[['Well Name','Latitude','Longitude','Formation','Thickness']]\n",
        "df_sub = df_sub.dropna()\n",
        "\n",
        "fig = px.scatter_mapbox(df_sub, lat=\"Latitude\", lon=\"Longitude\",\n",
        "                        color='Formation', \n",
        "                        zoom=5, height=600,\n",
        "                        hover_data={'Well Name': True,\n",
        "                                    'Latitude': False,\n",
        "                                    'Longitude': False,\n",
        "                                    'Formation': True,\n",
        "                                    'Thickness': True}\n",
        "                        )\n",
        "fig.update_layout(mapbox_style=\"open-street-map\")\n",
        "fig.update_layout(margin={\"r\":200,\"t\":20,\"l\":200,\"b\":0})\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_gvYbe7sR9I"
      },
      "source": [
        "![Damn](https://media1.tenor.com/images/3e64ea8c3ee1147ec50376620f984792/tenor.gif?itemid=5580082)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpDwDOz-DRbx"
      },
      "source": [
        "# Now you try a plotly map! \n",
        "\n",
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZZMJrUvDZdE"
      },
      "source": [
        "So, see, being a fancy data scientist isn't rocket science, it's mostly just googling things. \n",
        "![Googling is half](https://img.ifunny.co/images/072cea68327e54d5816c1a2f921f2958440586b2da0af7e9656f5255d2c7ab7b_1.jpg)\n",
        "\n",
        "---------\n",
        "\n",
        "# The End\n",
        "Hope this has been a useful tutorial, and don't forget to visit Zane's [research group website!](https://core.mines.edu) and the [Crude Audacity podcast](https://podcasts.apple.com/us/podcast/the-crude-audacity/id1480993402)\n",
        "\n",
        "![Work here is done](https://media1.tenor.com/images/168afe17abdf88b0d439c901f134a6f4/tenor.gif?itemid=4705793)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J7Cdgsp1_1Y"
      },
      "source": [
        "# BONUS! From Kristopher Purens\n",
        "# Doesn't work right in Colab though...\n",
        "\n",
        "!pip install ipyleaflet\n",
        "import ipyleaflet\n",
        "\n",
        "m = ipyleaflet.Map(\n",
        "    center=(30,-100),\n",
        "    zoom=5\n",
        "    )\n",
        "\n",
        "bm_macrostrat = { 'url': 'https://tiles.macrostrat.org/carto/{z}/{x}/{y}.png', \n",
        "                 'max_zoom': 20, 'attribution': '<a href=\"https://macrostrat.org/\">Macrostrat</a>', \n",
        "                 'name': 'Macrostrat'\n",
        "                 } \n",
        "\n",
        "macrostrat_layer = ipyleaflet.basemap_to_tiles(bm_macrostrat) \n",
        "\n",
        "m.add_layer(macrostrat_layer)\n",
        "\n",
        "m\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR-WaDqF0xVt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGe1FhAFe_GH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}