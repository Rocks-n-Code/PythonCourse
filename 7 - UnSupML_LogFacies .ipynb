{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "7 - UnSupML_LogFacies .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocks-n-Code/PythonCourse/blob/master/7%20-%20UnSupML_LogFacies%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDj4qEiLNzPi"
      },
      "source": [
        "# Log Facies with Unsupervised Machine Learning\n",
        "---\n",
        "## K-Means Clustering\n",
        "\n",
        "##### _A [recording](https://youtu.be/_DTN5ZhjJCY?t=4930) of a walkthrough of this notebook is avalible via AAPG Energy Minerals Division's Freeware for Freelancers lecture._\n",
        "---\n",
        "K-Means clustering is a commonly used method to assign points to a cluster. This is done by minimizing the Euclidean distance to the centeroid of each cluster. K, or the number of clusters, is defined by the user. For our example we'll optimize the number of clusters by minimizing the (squared) diffrence between from each cluster's centeroid, or within-sum-of-squares (WSS), and the similarity to a cluster with dismilarity to neighboring clusters with a silouette score. The silhouette score has a range from -1 to 1 with an optimum score being 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU7KB-yLN6Qt"
      },
      "source": [
        "pip install lasio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S18q57C2NzPj"
      },
      "source": [
        "import pandas as pd\n",
        "import lasio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "%matplotlib inline\n",
        "pd.options.display.max_columns = 999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68RcVYKbNzPm"
      },
      "source": [
        "Load in our data from an LAS log and fix some bad values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl2p7krbNzPo"
      },
      "source": [
        "las = lasio.read(\"https://raw.githubusercontent.com/Rocks-n-Code/PythonCourse/master/data/4210932323_ENCANA_DELAWARE_61_T1_16_1H_LAS.las\")\n",
        "las_df = las.df()\n",
        "\n",
        "#Getting rid of some bad values\n",
        "las_df = las_df.replace(-936.7891,np.NaN)\n",
        "las_df = las_df.replace(-624.4871,np.NaN)\n",
        "las_df = las_df.replace(-187.2639,np.NaN)\n",
        "\n",
        "#Preview our data\n",
        "las_df.loc[2000:2002]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S253bJb6NzPq"
      },
      "source": [
        "For the purpose of demonstration let's only use some of the information. Once we seperate out 1000' to work with let's reduce the influence of different units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5GQu1-wNzPr"
      },
      "source": [
        "#Pulling a subset to work with\n",
        "X = las_df.loc[2000:3000,['GR','MSFL','LLS','LLD','DPHI','NPHI','PE']]\n",
        "\n",
        "#Dimensionality Reduction\n",
        "scaler = MinMaxScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X), index=X.index, columns=X.columns)\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBWq8oB9NzPs"
      },
      "source": [
        "Notice that we've made a copy of the LAS dataframe and that the units are now between 0-1.\n",
        "\n",
        "---\n",
        "\n",
        "## Silhoutte Score\n",
        "\n",
        "We'll now do some testing with the Silhoutte Score to try and find an appropriate number of log facies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "zs3vBsLINzPt"
      },
      "source": [
        "k = list(range(2,13))\n",
        "score=[]\n",
        "\n",
        "for n_cluster in k:\n",
        "    km = KMeans(n_clusters=n_cluster).fit(X)\n",
        "    silhouette_avg = silhouette_score(X, km.labels_)\n",
        "    score.append(silhouette_score(X, km.labels_))\n",
        "\n",
        "plt.plot(k, score, 'o-')\n",
        "plt.xlabel(\"Clusters (k)\")\n",
        "plt.ylabel(\"Silhouette Score\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh3HJpTyNzPv"
      },
      "source": [
        "Note the high peak at k=4.\n",
        "\n",
        "---\n",
        "\n",
        "##  WSS & Elbow Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHFPJPZ3NzPv"
      },
      "source": [
        "inertias = []\n",
        "for i in k:\n",
        "    km = KMeans(n_clusters=i)\n",
        "    km.fit(X)\n",
        "    inertias.append(km.inertia_)\n",
        "plt.plot(k, inertias)\n",
        "plt.xlabel(\"Clusters\")\n",
        "plt.ylabel(\"Within Sum of Square\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnUPyBl6NzPx"
      },
      "source": [
        "We are looking for where the \"elbow\" is in the WSS, or approximately 5.\n",
        "\n",
        "---\n",
        "\n",
        "## K-Means\n",
        "\n",
        "Now that we've chosen a number of clusters to use we can fit our model and display our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZBDnqdxNzPx"
      },
      "source": [
        "km = KMeans( n_clusters=4 )\n",
        "km.fit(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5ptNzjCNzPz"
      },
      "source": [
        "Let's also calculate the euclidean distances between each point and their respective cluster centeroid.  This will give us a log to display to measure the fit of each depth to it's cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM7gbQQyNzP0"
      },
      "source": [
        "#Write the cluster labels to a column in the df\n",
        "labels = km.labels_\n",
        "X['FACIES'] = labels\n",
        "\n",
        "clsts = list(set(labels.astype(np.float64)))\n",
        "log_cols = ['GR','MSFL','LLS','LLD','DPHI','NPHI','PE']\n",
        "x = X.shape[0]\n",
        "X['euc_dis'] = np.nan\n",
        "for i, clst in enumerate(clsts):\n",
        "\n",
        "    #Center of cluster i\n",
        "    centers = [km.cluster_centers_[i]]\n",
        "\n",
        "    #Calculate distance of all points to center i; write to temp col in df\n",
        "    X['temp'] = euclidean_distances(X[log_cols].values, centers)\n",
        "\n",
        "    #Place those euclidean distances where the df's col FACIES is == to i\n",
        "    X['euc_dis'] = X['euc_dis'].where(X['FACIES'] != i, other=X['temp'])\n",
        "\n",
        "#Drop temp column\n",
        "X.drop(columns=['temp'],inplace=True)\n",
        "\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30nCEXTpNzP2"
      },
      "source": [
        "While the computer works better with scaled log values we are use to reading well log values. Let's write the original (Un-Reduced) log values back to X for our plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrrCl1XFNzP2"
      },
      "source": [
        "X[['GR','MSFL','LLS','LLD','DPHI','NPHI','PE']] = las_df.loc[2000:3000,['GR','MSFL','LLS','LLD','DPHI','NPHI','PE']]\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT87bMMvNzP4"
      },
      "source": [
        "To make it easier to plot these logs I've included some original and some tweaked functions for our purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0,
          6,
          23,
          71
        ],
        "id": "ajIQvpsbNzP4"
      },
      "source": [
        "def rect(ax,x,y,w,h,c):\n",
        "    #Make rectangle with plt.Rectangle((x,y@ Lower left),width,height,color)\n",
        "    polygon = plt.Rectangle((x,y),w,h,color=c)\n",
        "    #Add it to axis\n",
        "    ax.add_patch(polygon)\n",
        "\n",
        "def GR_fill(ax,X,Y):\n",
        "    plt.plot(X,Y,lw=0)\n",
        "\n",
        "    #Make a custom color ramp\n",
        "    cmap = mpl.colors.LinearSegmentedColormap.from_list(\"\", [\"yellow\",\"yellow\",'goldenrod','darkgoldenrod',\"dimgrey\",'black','black'])\n",
        "\n",
        "    #Step distance\n",
        "    dy = Y[1]-Y[0]\n",
        "\n",
        "    #Max GR value\n",
        "    N  = float(X.max())\n",
        "\n",
        "    #Make rectangles with color based on GR values\n",
        "    for n, (x,y) in enumerate(zip(X,Y)):\n",
        "        color = cmap(x/N)\n",
        "        rect(ax,x,y,N-x,dy,color)\n",
        "\n",
        "def log_plot(X, GR, MSFL, LLS, LLD, DPHI, NPHI, PE, FACIES, EucD):\n",
        "    '''\n",
        "    X: df, Dataframe of log values and cluster output.\n",
        "    GR,MSFL,LLS,LLD,DPHI,NPHI,PE,FACIES,EucD: str, Col names\n",
        "\n",
        "    This is a tweaked version of Brendon Hall's log plot.  If you haven't read the article you really should:\n",
        "    https://csegrecorder.com/articles/view/geochemical-facies-analysis-using-unsupervised-machine-learning\n",
        "    Brilliant guy and good human being. Stop by ENTHOUGHT's booth next time you're at a conference and say hi!\n",
        "    '''\n",
        "    cluster=np.repeat(np.expand_dims(X[FACIES].values,1), 100, 1)\n",
        "\n",
        "    ztop=X.index.min(); zbot=X.index.max()\n",
        "    f, ax = plt.subplots(nrows=1, ncols=5, figsize=(10, 13))\n",
        "\n",
        "    ##GR - PE\n",
        "    ax[0].plot(X[GR],X.index,color='k')\n",
        "\n",
        "    #GR Fill\n",
        "    GR_fill(ax[0],X[GR],X.index)\n",
        "\n",
        "    #PE\n",
        "    ax1_2 = ax[0].twiny()\n",
        "    ax1_2.plot(X[PE], X.index,color='blue',alpha=0.5)\n",
        "    f.text(0.2,0.91,\"GR\", ha=\"left\", va=\"bottom\", size=\"medium\",color=\"black\")\n",
        "    f.text(0.2,0.90,\"PE\", ha=\"left\", va=\"bottom\", size=\"medium\",color=\"blue\",alpha=0.5)\n",
        "\n",
        "    ##Resistivity\n",
        "    ax[1].plot(X[MSFL], X.index,color='lightgrey')\n",
        "    ax[1].plot(X[LLS], X.index,color='grey')\n",
        "    ax[1].plot(X[LLD], X.index,color='k')\n",
        "    ax[1].set_xscale(\"log\",\n",
        "                     #nonposx='clip'\n",
        "                     ) #log scale\n",
        "    f.text(0.35,0.92, \"MSFL\", ha=\"left\", va=\"bottom\", size=\"medium\",color=\"lightgrey\")\n",
        "    f.text(0.35,0.91, \"LLS\", ha=\"left\", va=\"bottom\", size=\"medium\",color=\"grey\")\n",
        "    f.text(0.35,0.90, \"LLD\", ha=\"left\", va=\"bottom\", size=\"medium\",color=\"k\")\n",
        "\n",
        "    ##Porosity\n",
        "    ax[2].plot(X[NPHI], X.index,color='blue')\n",
        "    ax[2].plot(X[DPHI], X.index,color='red')\n",
        "    f.text(0.5,0.91,\"NPHI\", ha=\"left\", va=\"bottom\", size=\"medium\",color=\"blue\")\n",
        "    f.text(0.5,0.90,\"DPHI\", ha=\"left\", va=\"bottom\", size=\"medium\",color=\"red\")\n",
        "\n",
        "    ##Euclidean distance to cluster centers\n",
        "    ax[3].plot(X[EucD], X.index, '-', color='r')\n",
        "    f.text(0.65,0.90,\"EucD\", ha=\"left\", va=\"bottom\", size=\"medium\",color=\"k\")\n",
        "\n",
        "    #Facies\n",
        "    #Assigning the colors to the cluster just for this example\n",
        "    colorlist = []\n",
        "    for facies in sorted(X.FACIES.unique().tolist()):\n",
        "        if X['PE'][X.FACIES==facies].mean() > 4:\n",
        "            colorlist.append('deepskyblue')\n",
        "\n",
        "        elif 100 > X['GR'][X.FACIES==facies].mean() > 65:\n",
        "            colorlist.append('peru')\n",
        "\n",
        "        elif X['GR'][X.FACIES==facies].mean() > 100:\n",
        "            colorlist.append('dimgrey')\n",
        "        else:\n",
        "            colorlist.append('gold')\n",
        "    cmap = mpl.colors.ListedColormap(colorlist, name='from_list', N=None)#plt.get_cmap('Dark2')\n",
        "    im=ax[4].imshow(cluster, interpolation='none', aspect='auto',\n",
        "                    cmap=cmap,vmin=0,vmax=4)\n",
        "    f.text(0.8,0.90,\"FACIES\", ha=\"left\", va=\"bottom\", size=\"medium\",color=\"k\")\n",
        "\n",
        "    #Set repeat tasks with loop\n",
        "    for i in range(len(ax)-1):\n",
        "        ax[i].set_ylim(ztop,zbot)\n",
        "        ax[i].invert_yaxis()\n",
        "        ax[i].grid()\n",
        "        try:\n",
        "            ax[i].locator_params(axis='x', nbins=3) #doesn't seem to like por... hmmm\n",
        "        except: pass\n",
        "\n",
        "    ax[0].set_ylabel('MD [ft]', fontsize=16)\n",
        "    ax[0].grid(False)\n",
        "    ax[1].grid(False)\n",
        "    ax[2].grid(False)\n",
        "    ax[3].grid(False)\n",
        "    ax[1].set_yticklabels([]); ax[2].set_yticklabels([]); ax[3].set_yticklabels([])\n",
        "    ax[4].set_yticklabels([]);\n",
        "    ax[4].set_xticklabels([])\n",
        "\n",
        "log_plot(X,'GR','MSFL','LLS','LLD','DPHI','NPHI','PE','FACIES','euc_dis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipok9ZpsNzP6"
      },
      "source": [
        "- Where do you see limestones?\n",
        "- Where do you see mudstones?\n",
        "- Where do you see sandstones?\n",
        "- Where do you see potential source rocks?\n",
        "- How do those compare to the cluster families?\n",
        "- Are there unique beds that don't fit their facies well?\n",
        "\n",
        "---\n",
        "\n",
        "# Give It A Try\n",
        "\n",
        "Retrain the K-Means model with different numbers of clusters and plot your results. What zones do you see diffrences? What zones stay the same?  Bonus round: Try to train the model with spectral gamma and compare your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHQolmlINzP6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}