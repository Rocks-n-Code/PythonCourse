{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t20-subsurface-intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocks-n-Code/PythonCourse/blob/master/5%20-%20Lasio%20%26%20Striplog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkBtOfXppH8m"
      },
      "source": [
        "[<Back](https://colab.research.google.com/github/Rocks-n-Code/PythonCourse/blob/master/4%20-%20Geospatial%20Mapping.ipynb) [Next>](https://colab.research.google.com/github/Rocks-n-Code/PythonCourse/blob/master/6%20-%20Scraping%20Data.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFCuwz_4uGs8"
      },
      "source": [
        "# 5 - Lasio & Striplog \r\n",
        "## by Thomas Martin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaVKCLh5uXce"
      },
      "source": [
        "Adapted from Thomas's talk at Transform 2020 - [Video](https://youtu.be/oytSwhqvKbc) - [Repo](https://github.com/ThomasMGeo/Transform2020)\n",
        "\n",
        "![Thomas Martin](https://github.com/Rocks-n-Code/PythonCourse/blob/master/img/TM130160.jpg?raw=true)\n",
        "\n",
        "[Thomas Martin](https://twitter.com/ThomasM_geo) is a graduate student at [Colorado School of Mines](https://www.mines.edu/), in the [CoRE](https://core.mines.edu/) research group. He is working on core-log automated interepertation using machine learning. Feel free to reach out on [twitter](https://twitter.com/ThomasM_geo) or catch him on the software underground slack! \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj8t-AXB0nNn"
      },
      "source": [
        "There are whole classes devoted to basic python syntax, loops, functions, etc. This class is to just get you up and running with some key basics that can help with basic projects. Join us on the slack for some pointers!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcKP1Y8ZxUEB"
      },
      "source": [
        "## Importing and Using Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPWwh2HXxVmy"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-aVqCH6yMQe"
      },
      "source": [
        "Importing a few others that I use in (almost) every project. We can import them normally becuase Google pre-loaded them. Google does not pre-load everything that you need, sometimes you might need to install it.  ~*warning* ~ not every package can easily be imported in Colab. I have not figured out what makes some go and some not. But stats and plotting is usually pretty safe. Niche, one off, old, academic code, less so. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GVjJfbUxo7R"
      },
      "source": [
        "!pip install lasio # the ! before the pip is important, also this is a shell command, not a python one"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWaC0LxVyWQW"
      },
      "source": [
        "Just installed the lasio package using pip. Lasio is a .las file imput and output reader. It's a great way to read in a .las file (well logs, not LiDAR) to use in python. After installing it, you still need to import it. The github for lasio is [here](https://github.com/kinverarity1/lasio)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qpm6NlMyQsD"
      },
      "source": [
        "import lasio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clpopEZGziBZ"
      },
      "source": [
        "There are hundreds of packages, not all of them work with Colab. We will install and import packages throughout the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km-2ZX7pF_h2"
      },
      "source": [
        "# Well log input and output using lasio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xS1PNakIi-g"
      },
      "source": [
        "lasio (.las input and output) is one of my all time favorite packages. It's updated often, and it works 99.5% of the time with .las files (well logs, not LiDAR data). The repo is [here](https://github.com/kinverarity1/lasio) on github. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7E2EqpeIic2"
      },
      "source": [
        "las = lasio.read('https://raw.githubusercontent.com/ThomasMGeo/Transform2020/master/t20-intro/4900722147_722147B.las')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txaa55DxKDrr"
      },
      "source": [
        "We just read in a las file! Let's do a quick quaility control, and make some plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHOhO8R3Vq-E"
      },
      "source": [
        "dir(las)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBR-V203Vvbk"
      },
      "source": [
        "So there is a lot of stuff going on with the las object we just created. Which is awesome! But can be daunting to get into what you are looking for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkTyhx2WJ-ed"
      },
      "source": [
        "las.curves"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1QvFJ5pb3Yf"
      },
      "source": [
        "Wow, this well has a lot of curves! OK, we are going to make a data frame for the data in the .las file. This will behave really similar to the previous data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07Vv8C-3KFWj"
      },
      "source": [
        "data = las.df() # This time we named the dataframe data and not df\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFV_WvFJKegu"
      },
      "source": [
        "Scroll around! If you want to get a handle on stats of your well curves, using the describe function on a dataframe is awesome. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o54RFQxzPeoK"
      },
      "source": [
        "data.to_csv('well_data.csv') # just saved it out!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edr96Ez9O3d7"
      },
      "source": [
        "Once this is in a data frame, you can export the curve data as a csv! This can be used in excel, spotfire, matlab or any other program you are more familiar with. This alone saves tons of time! While I prefer python, I know it's not for everyone."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYIJvIteKatN"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEZRBNCCYKfK"
      },
      "source": [
        "If you want different percentiles in df.describe, you can pass those values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ATukdSaYD7Z"
      },
      "source": [
        "data.describe(percentiles=[0.1, 0.5, 0.9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8fYijj0OxGd"
      },
      "source": [
        "If you want to save out this table as a csv, you can do that in one line:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypBfvWdZOm67"
      },
      "source": [
        "data.describe().to_csv(\"petro-stats.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWf-Cn4qK5s8"
      },
      "source": [
        "data.AHO10.min() # If you just want one of the stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xf9-P3pNA3H"
      },
      "source": [
        "Let's use the quantile function to make some quick cutoffs (will be used in the future)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtkrAj0ULbrU"
      },
      "source": [
        "lowGR = data.GR.quantile(.20)\n",
        "lowGR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmND25DeME16"
      },
      "source": [
        "highRES = data.AHO90.quantile(.95)\n",
        "highRES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epZJ6d08Pzfs"
      },
      "source": [
        "Feel free to make your own cutoffs here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y7RJBGINS4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MJtiQniNmo5"
      },
      "source": [
        "### Plotting up well log data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Bi0m4YNoNJ"
      },
      "source": [
        "# Cross plot comparing GR to Deep Resistivity\n",
        "plt.figure(figsize=(5,4), dpi=100) # figure size and dpi you can set here\n",
        "plt.scatter(data.GR.values, data.AHO90.values, color='blue', marker='.', alpha=0.3)\n",
        "plt.yscale('log') #log scale for Y axis\n",
        "\n",
        "plt.grid(True)\n",
        "plt.xlabel('GR', size=16)\n",
        "plt.ylabel('Deep Resistivity', size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKQoCqthdhqM"
      },
      "source": [
        "# lets make a histogram of the GR Curve, with 20 bins, in green\n",
        "plt.hist(data.GR.values, bins = 20, color='g', alpha = 0.5)\n",
        "plt.xlabel('GR', size=16)\n",
        "plt.ylabel('Count', size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL3qgjHoeZDm"
      },
      "source": [
        "# line plot of the Gamma curve\n",
        "plt.figure(figsize=(4,8), dpi=100)\n",
        "plt.plot(data.GR.values, data.index, color='g')\n",
        "plt.ylabel('Depth in Feet', size=16)\n",
        "plt.ylim(2000,0)\n",
        "plt.grid(True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtSEUgGzzSXS"
      },
      "source": [
        "Let's add a depth track for deep resistivity, a title and a few other additional widigits. Also we will use the well name for the title:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJvsTdb1_tOu"
      },
      "source": [
        "las.header['Well'].WELL.value # we can pull the well name directly from the header"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gef-2TAez7E0"
      },
      "source": [
        "# line plot of the Gamma curve\n",
        "plt.figure(figsize=(6,7), dpi=100)\n",
        "\n",
        "plt.suptitle(las.header['Well'].WELL.value, size =16) # overall title\n",
        "\n",
        "plt.subplot(121) # if we are going to make two plots, matplotlib calls it a subplot\n",
        "plt.plot(data.GR.values, data.index, color='g') # the actual plot!\n",
        "plt.ylabel('Depth in Feet', size=16)\n",
        "plt.xlabel('API', size=16)\n",
        "plt.ylim(2000,0) # the limit is reversed to go deep down\n",
        "plt.grid(True) # Turning the grid on\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(data.AHO10.values, data.index, color='grey')\n",
        "plt.plot(data.AHO90.values, data.index, color='black')\n",
        "plt.xscale('log')\n",
        "plt.grid(True)\n",
        "plt.xlim(0.4,4000)\n",
        "plt.ylim(2000,0)\n",
        "plt.xlabel('OhmM', size=16)\n",
        "plt.tick_params(labelleft=False)  \n",
        "\n",
        "plt.savefig('awesome-plot.pdf', dpi=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKrLZTmDgAmi"
      },
      "source": [
        "Let's add a pay flag, remember the cutoffs we calcualted above? Let's use those. Using pythonic nomenclature, we will set a true flag, only when both conditions are met."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNjH3HDSVsxj"
      },
      "source": [
        "payMapper = (data.GR.values <= lowGR) & (data.AHO90.values >= highRES)\n",
        "np.unique(payMapper)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHOnuLS5LpFS"
      },
      "source": [
        "If we want to see how many true and false statements there are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYVkxbLtLk3f"
      },
      "source": [
        "np.bincount(payMapper) # your specific numbers might be a bit different"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP5-eLVgkHGH"
      },
      "source": [
        "So the GR values have to be below the cutoff, and resistivity have to be above the cutoff."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycGj3S7ZhN-j"
      },
      "source": [
        "# line plot of the Gamma curve\n",
        "plt.figure(figsize=(5,8), dpi=100)\n",
        "\n",
        "plt.subplot(131) # the subplot changed to allow for 3 columns\n",
        "plt.plot(data.GR.values, data.index, color='g')\n",
        "plt.ylabel('Depth in Feet', size=16)\n",
        "plt.xlabel('API', size=16)\n",
        "plt.ylim(2000,0)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(132) # this is the new pay flag plot\n",
        "plt.fill_between(payMapper, data.index, color='red') # used fill between, not plot\n",
        "plt.ylim(2000,0)\n",
        "plt.tick_params(labelleft=False)  \n",
        "plt.xlabel('Pay Flag', size=16)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.plot(data.AHO90.values, data.index, color='black')\n",
        "plt.xscale('log')\n",
        "plt.grid(True)\n",
        "plt.xlim(0.4,4000)\n",
        "plt.ylim(2000,0)\n",
        "plt.xlabel('OhmM', size=16)\n",
        "plt.tick_params(labelleft=False)  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js-ScaoWjGfb"
      },
      "source": [
        "Little heavy on the pay flag! But a good template for future work. Can be used for any sort of cutoff, or statistical analysis. Mess around with a plot below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4lvntH-U_Cy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5zQpsWxSfy"
      },
      "source": [
        "# Striplog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udd77REeyB_I"
      },
      "source": [
        "Striplog is an awesome package for  basic graphic logs, stratigraphic information, formations, and other geo stuff. The github is [here](https://github.com/agile-geoscience/striplog). This heavily borrows from [tutorials](https://github.com/agile-geoscience/striplog/tree/master/tutorial)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEKJUNO8xUcj"
      },
      "source": [
        "!pip install striplog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv2DpRBSyzyE"
      },
      "source": [
        "import striplog\n",
        "striplog.__version__ #if this fails, just re run the above cells"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aWoVp2-zUau"
      },
      "source": [
        "### Lexicon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ePFvbCHTM_r"
      },
      "source": [
        "Striplog has a lot of geowords already preloaded. Think sand, shale, mudstone, salt, etc:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfxPTtexy7B-"
      },
      "source": [
        "from striplog import Lexicon\n",
        "print(Lexicon.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIl_q_WOzSw3"
      },
      "source": [
        "lexicon = Lexicon.default()\n",
        "lexicon #scroll around!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wplg43oQzZsS"
      },
      "source": [
        "lexicon.synonyms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlhXQJhOT_Sm"
      },
      "source": [
        "These abbrevations are common for mudlogs, there is a great turtorial on the github if you are interested in that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrVURU9VzsVr"
      },
      "source": [
        "s = \"grysh gn ss w/ sp gy sh\"\n",
        "lexicon.expand_abbreviations(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chYLbMkC0IuB"
      },
      "source": [
        "### Componet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVv1JwfczxvL"
      },
      "source": [
        "from striplog import Component"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXZ8U4J_0NdL"
      },
      "source": [
        "print(Component.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDdBXxnK0z0g"
      },
      "source": [
        "We define a new rock with a Python dict object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afhsP2F_0WFj"
      },
      "source": [
        "r = {'colour': 'grey',\n",
        "     'grainsize': 'vf-f',\n",
        "     'lithology': 'sand'}\n",
        "rock = Component(r)\n",
        "rock"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DCRYRW409Sx"
      },
      "source": [
        "You can now call these componets!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngMolD_Q0yao"
      },
      "source": [
        "rock['colour'] # who spelled this?! < Matt Hall/>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBFGy1lw07YQ"
      },
      "source": [
        "rock.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1EFdIy__Sue"
      },
      "source": [
        "rock.summary(fmt=\"My rock: {lithology} ({colour}, {grainsize!u})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqUDg4me_Zu-"
      },
      "source": [
        "\n",
        "\n",
        "The formatting supports the usual s, r, and a:\n",
        "\n",
        "    s: str\n",
        "    r: repr\n",
        "    a: ascii\n",
        "\n",
        "Also some string functions:\n",
        "\n",
        "    u: str.upper\n",
        "    l: str.lower\n",
        "    c: str.capitalize\n",
        "    t: str.title\n",
        "\n",
        "And some numerical ones, for arrays of numbers:\n",
        "\n",
        "    + or ∑: np.sum\n",
        "    m or µ: np.mean\n",
        "    v: np.var\n",
        "    d: np.std\n",
        "    x: np.product\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZnIvwCOA3I8"
      },
      "source": [
        "### Position"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1HBWOlCBtwU"
      },
      "source": [
        "Positions define points in the earth, like a top, but with uncertainty. You can define:\n",
        "\n",
        "    upper — the highest possible location\n",
        "    middle — the most likely location\n",
        "    lower — the lowest possible location\n",
        "    units — the units of measurement\n",
        "    x and y — the x and y location (these don't have uncertainty, sorry)\n",
        "    meta — a Python dictionary containing anything you want\n",
        "\n",
        "Positions don't have a 'way up'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVYJBakwAuno"
      },
      "source": [
        "from striplog import Position\n",
        "print(Position.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiRIlnIGBy_H"
      },
      "source": [
        "params = {'upper': 95,\n",
        "          'middle': 100,\n",
        "          'lower': 110,\n",
        "          'meta': {'kind': 'erosive', 'source': 'DOE'}\n",
        "          }\n",
        "\n",
        "p = Position(**params)\n",
        "p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJe61woyB-dA"
      },
      "source": [
        "Even if you don't give a middle, you can always get z: the central, most likely position:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdqZiqVJB2Ia"
      },
      "source": [
        "params = {'upper': 75, 'lower': 85}\n",
        "p = Position(**params)\n",
        "p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNY8bCnJB5pR"
      },
      "source": [
        "p.z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhRxFHfyD-IK"
      },
      "source": [
        "## Let's make a striplog!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8J72ScVUgKr"
      },
      "source": [
        "I just introduced a bunch of boring things about dictionaries, etc. What makes this nice once you get it setup, is you can make some templates for common formations and lithotypes. We are going to do a simple one from this [github](https://github.com/ThomasMGeo/CSV2Striplog)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XP_HqNOEA68"
      },
      "source": [
        "from striplog import Lexicon, Decor, Component, Legend, Interval, Striplog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZb0Cp87Xq0-"
      },
      "source": [
        "\n",
        "### Make a legend\n",
        "\n",
        "Most of the stuff in the dicts you made were about display — so they are going to make Decor objects. A collection of Decors makes a Legend. A Legend determines how a striplog is displayed.\n",
        "\n",
        "First I'll make the components, since those are easy. I'll move 'train' into there too, since it is to do with the rocks, not the display. If it seems weird having 'train' in the Component (which is really supposed to be about direct descriptions of the rock, but the idea is that it's always the same for all specimens of that rock so it does fit here) then you could put it in data instead.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcknjhAREDMS"
      },
      "source": [
        "facies = {\n",
        "    's': Component({'lithology': 'sandstone', 'train':'y'}),\n",
        "    'i': Component({'lithology': 'interbedded', 'train':'y'}),\n",
        "    'sh': Component({'lithology': 'shale', 'train':'y'}),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E90MLt41QVum"
      },
      "source": [
        "The next block of text could be less lines of code. The indenting is just a way to make it easier to read. Everyone has there own style of programming. We are just setting the decor of our future striplog plot. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAmbodZEGDub"
      },
      "source": [
        "sandstone = Decor({\n",
        "    'component': facies['s'],\n",
        "    'colour': 'yellow',\n",
        "    'hatch': '.',\n",
        "    'width': '3',\n",
        "})\n",
        "\n",
        "interbedded = Decor({\n",
        "    'component': facies['i'],\n",
        "    'colour': 'darkseagreen',\n",
        "    'hatch': '--',\n",
        "    'width': '2',\n",
        "})\n",
        "\n",
        "shale = Decor({\n",
        "    'component': facies['sh'],\n",
        "    'colour': 'darkgray',\n",
        "    'hatch': '-',\n",
        "    'width': '1',\n",
        "})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUkb8iyjEHsC"
      },
      "source": [
        "legend = Legend([sandstone, interbedded, shale])\n",
        "legend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwgUCa6eiNO8"
      },
      "source": [
        "#Read in file to Colab instance\r\n",
        "loc = 'https://raw.githubusercontent.com/ThomasMGeo/Transform2020/master/t20-intro/t20-lith.csv'\r\n",
        "lith = pd.read_csv(loc)\r\n",
        "lith.to_csv('t20-lith.csv',\r\n",
        "            index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdZINUZ9FJ8C"
      },
      "source": [
        "strip = Striplog.from_csv('t20-lith.csv')\n",
        "strip[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIafor_hZmOo"
      },
      "source": [
        "\n",
        "##Deal with lithology¶\n",
        "\n",
        "The lithology has been turned into a component, but it's using the abbreviation... I can't figure out an elegant way to deal with this so, for now, we'll just loop over the striplog and fix it. We read the data item's lithology ('s' in the top layer), then look up the correct lithology name in our abbreviation dictionary, then add the new component in the proper place. Finally, we delete the data we had.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQAFZ8TvbCj6"
      },
      "source": [
        "strip[0].data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RfW9CKNN2jq"
      },
      "source": [
        "for s in strip:\n",
        "    lith = s.data['lithology']\n",
        "    s.components = [facies[lith]]\n",
        "    s.data = {}\n",
        "# Run once, not twice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic1z-rx1sOr8"
      },
      "source": [
        "strip[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIDZuhx9QD9X"
      },
      "source": [
        "strip.plot(legend)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omZz8U_esVcU"
      },
      "source": [
        "Just plotted a simple strip log from a CSV! You can make striplogs 100 different ways, and I highly reccomend the turtorials on the github for more exploration. Striplog is a fun package to dig into (pun intended) as it forces you to think about how this data is stored, managed, and used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a34Bkt2qEKr"
      },
      "source": [
        "[<Back](https://colab.research.google.com/github/Rocks-n-Code/PythonCourse/blob/master/4%20-%20Geospatial%20Mapping.ipynb) [Next>](https://colab.research.google.com/github/Rocks-n-Code/PythonCourse/blob/master/6%20-%20Scraping%20Data.ipynb)"
      ]
    }
  ]
}