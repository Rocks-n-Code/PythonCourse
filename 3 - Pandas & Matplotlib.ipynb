{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "3 - Pandas & Matplotlib.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocks-n-Code/PythonCourse/blob/master/3%20-%20Pandas%20%26%20Matplotlib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHzbqyItJI8V",
        "colab_type": "text"
      },
      "source": [
        "# Pandas and Matplotlib\n",
        "In this section we'll introduce pandas, and making figures in matplotlib.\n",
        "\n",
        "To get started with our code we'll import the libraries we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fI2fxmUJI8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "#Enable plots to show up in the jupyter notebook\n",
        "%matplotlib inline\n",
        "\n",
        "#Increase the number of columns that will display\n",
        "pd.options.display.max_columns = 50\n",
        "\n",
        "#Set the size of our plots\n",
        "phi = (1 + 5 ** 0.5) / 2\n",
        "plt.rcParams['figure.figsize'] = [10*phi, 10]\n",
        "#You can also comment in code cells by using \"#\" to ignore the line. Useful for testing too."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-HKG8a2JI8Z",
        "colab_type": "text"
      },
      "source": [
        "We'll then need to load our file into a pandas \"dataframe.\" Pandas will try to automatically tell what type of data is in each column. We want to preserve the \"0\" in our API numbers so we'll want them treated like a string rather than a number so we must tell pandas what type of data is in that column the the `dtype` variable.  We'll be using data from the [USGS Core Research Center](https://www.usgs.gov/core-science-systems/nggdp/core-research-center) in Lakewood, CO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsuQA9_vJI8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = 'https://raw.githubusercontent.com/Rocks-n-Code/PythonCourse/master/data/cores.csv'\n",
        "data_types = {'API Num':str}\n",
        "df = pd.read_csv(file_path, dtype=data_types)\n",
        "df.shape #(Row count, Columns count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK9IVTQDJI8c",
        "colab_type": "text"
      },
      "source": [
        "We see that we have 16,321 rows and 25 columns of data. To preview the data lets increase the number of displayed columns and  then we'll use the ```python df.head()```  command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPb9a2_qJI8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preview our data\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNqrrEgbJI8f",
        "colab_type": "text"
      },
      "source": [
        "We can select data we wish to work with from our dataframe to create a \"series.\"  This can be done with locations in the dataframe or with filters. When counting in Python `0` is the first number you start with. Let's look at the API number (column 7) 2nd row (index 1) using two different methods. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaKVBwtyJI8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df.at[1,'API Num'])\n",
        "print(df.iloc[1,7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwjGfIiJJI8h",
        "colab_type": "text"
      },
      "source": [
        "We can also filter to select data. Using one or mutliple criteria.  When we select a portion of a `DataFrame` we return a pandas `Series`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K1NJUpkJI8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[df['Field'] == 'JANICE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChdvhGFnJI8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[(df['Field'] == 'JANICE') & \n",
        "   (df['Source'] == 'CENTER OF SECTION') & \n",
        "   (df['Well Name'] == '1 HARRISON')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ac_OFGiJI8l",
        "colab_type": "text"
      },
      "source": [
        "Or we can define the column of data that we want. `Series.tolist()` will format our data into a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o2q5f-FJI8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['API Num'][(df['Field']=='JANICE')&(df['Source']=='CENTER OF SECTION')&(df['Well Name']=='1 HARRISON')].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX6dLPMMJI8p",
        "colab_type": "text"
      },
      "source": [
        "Now looking at this lets see how many cores are in each state with a loop. `Series.unique()` will return "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGA_3sw1JI8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states = df['State'][df['State'].notnull()].unique().tolist()\n",
        "total_count = 0\n",
        "state_counts = []\n",
        "\n",
        "#For loop\n",
        "for state in states:\n",
        "    #filter to those rows that are from the state in the loop, see the shape, take the row count\n",
        "    state_count = df[df.State == state].shape[0] \n",
        "    state_counts.append(state_count)\n",
        "    total_count += state_count\n",
        "    print(state,':',state_count)\n",
        "    \n",
        "null_rows = df[df['State'].isnull()].shape[0]\n",
        "print('Null :', null_rows)\n",
        "print('Total :', total_count + null_rows)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fSbkdz5JI8r",
        "colab_type": "text"
      },
      "source": [
        "Now let's take that same data and graph it with a bar graph in matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1QcGyTJJI8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = len(states)\n",
        "ind = np.arange(N)\n",
        "width = 0.35\n",
        "p1 = plt.bar(ind, state_counts, width)\n",
        "plt.ylabel('Cores')\n",
        "plt.title('Cores by State')\n",
        "plt.xticks(ind, states)\n",
        "plt.yticks(np.arange(0, 6001, 500))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OEEep46JI8t",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Example Two: Clay Typing\n",
        "\n",
        "In this example we will load some spectral gamma data, calculate vclay, and look at the K-Th ratio.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OD8mQx6JI8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Data & Set DEPT to Index\n",
        "las_df = pd.read_csv('https://raw.githubusercontent.com/Rocks-n-Code/PythonCourse/master/data/Spectral_GR.csv')\n",
        "las_df.set_index('DEPT',inplace=True)\n",
        "\n",
        "#Preview Data\n",
        "las_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MWDyUVIJI8v",
        "colab_type": "text"
      },
      "source": [
        "Let's calculate Vshale. First we'll get a clean GR reading from the clean sands around 585' and a GR reading for shale around 4835'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU8mSsrnJI8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GRclean = las_df[580:590]['GR'].mean()\n",
        "GRshale = las_df[4830:4840]['GR'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6XZLLJmJI8x",
        "colab_type": "text"
      },
      "source": [
        "Next we'll write a function for Vshale and apply it to our GR to make a new column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNYVI_YXJI8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Vshale(gr,GRclean=GRclean,GRshale=GRshale):\n",
        "    vshale = (gr - GRclean)/(GRshale-GRclean)\n",
        "    return vshale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NXvs8uPJI8z",
        "colab_type": "text"
      },
      "source": [
        "Next we will use `.apply(lambda x: <function>(x))` to calculate a new column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPygsHTlJI8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "las_df['VSHALE'] = las_df['GR'].apply(lambda x: Vshale(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDLQBnKuJI81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "las_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1BofYpmJI83",
        "colab_type": "text"
      },
      "source": [
        "Let's plot the spectral gamma in other plots to give us more information on what type of clays we are dealing with. We can utilize our Vshale calculation to see how different relative volumes of clay change with clay type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jspD-ppDJI83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Background Image\n",
        "im = plt.imread('https://github.com/Rocks-n-Code/PythonCourse/blob/master/img/3_KTHcrossplot_crop.png?raw=true')\n",
        "implot = plt.imshow(im)\n",
        "\n",
        "#Image is 689x411 pixels and 5x20 on scale\n",
        "colormap = plt.cm.gist_rainbow \n",
        "normalize = mpl.colors.Normalize(vmin=0, vmax=1)\n",
        "plt.scatter(las_df['POTA'].apply(lambda x: x*(689/5)),       #Scale to image size & scale\n",
        "            las_df['THOR'].apply(lambda x: -x*(411/20)+411), #Scale to image size & scale\n",
        "            s=48,               #Size of dot\n",
        "            c=las_df['VSHALE'], #column to use for color scale\n",
        "            cmap=colormap,      #color map\n",
        "            norm=normalize,\n",
        "            alpha=0.3)          #Alpha\n",
        "\n",
        "#Set Axis Scales\n",
        "plt.xticks([0,689], [0,5])      #change the x axis\n",
        "plt.yticks([411,0], [0,20])     #change the y axis\n",
        "\n",
        "#Set Axis Labels\n",
        "plt.xlabel('K (%)')             #label x axis\n",
        "plt.ylabel('Th (ppm)')          #label y axis\n",
        "\n",
        "#Set Color Bar\n",
        "cbar = plt.colorbar(shrink=0.5)\n",
        "cbar.set_label('VSHALE', rotation=90)\n",
        "\n",
        "#Show Plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IfFxB9XJI85",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Example Three: Maturity in North Dakota\n",
        "\n",
        "Lets take another look at some more data from the National Energy Geochemical Survey database. \n",
        "\n",
        "SOURCE: https://energy.usgs.gov/GeochemistryGeophysics/GeochemistryLaboratories/GeochemistryLaboratories-GeochemistryDatabase.aspx\n",
        "        \n",
        "\n",
        "KEY: https://mrdata.usgs.gov/geochem/about.php\n",
        "\n",
        "Let's open a text file of the analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "l-UIn9KgJI86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chem = pd.read_csv('https://raw.githubusercontent.com/Rocks-n-Code/PythonCourse/master/data/Analysis_abrv.csv', #Original was 3,138,631 rows and 191 Mb; smaller file used for online example.\n",
        "                   dtype={'OrderID':str,'SampleNumber':str,'AnalysisGroup':str,\n",
        "                          'Matrix':str,'Analysis':str,'Param':str,'Units':str,'Comments':str},\n",
        "                   encoding = \"ISO-8859-1\",\n",
        "                   low_memory=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9owPI0ZCJI87",
        "colab_type": "text"
      },
      "source": [
        "Preview your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pefnKussJI88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(chem.shape)\n",
        "chem.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsMmjKf6JI9A",
        "colab_type": "text"
      },
      "source": [
        "Let's filter down to only Rock-Eval data by filtering to the contents of a list with `.isin(<list>)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jApAgaZCJI9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make a list of values to filter to only rock-eval day.\n",
        "parms = ['OI', 'S1', 'S2', 'S3', 'TMAX', 'TOC', 'HI', 'S2S3', 'PI', 'PC']\n",
        "rockeval = chem[(chem['Analysis']=='Rock-Eval')&(chem['Param'].isin(parms))]\n",
        "print(rockeval.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpdPOZuxJI9C",
        "colab_type": "text"
      },
      "source": [
        "Now let open an excel file. We'll then calulate two new columns and merge more information about those samples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCxLkrPeJI9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Open an excel file to a dataframe\n",
        "samples = pd.read_excel('https://github.com/Rocks-n-Code/PythonCourse/blob/master/data/Samples.xlsx?raw=true',converters={'API':str})\n",
        "\n",
        "#Calculate TVD SS\n",
        "samples['TVDSS_top'] = samples['ELEVF'] - samples['TOPF']\n",
        "samples['TVDSS_bot'] = samples['ELEVF'] - samples['BOTF']\n",
        "\n",
        "#Preview the first three rows of the dataframe\n",
        "samples.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDmnDUs6JI9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORNfz80CJI9G",
        "colab_type": "text"
      },
      "source": [
        "Lets make sure the data is in the correct format and merge the two dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BsOyLttJI9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set the columns to a string format\n",
        "rockeval['SampleNumber'] = rockeval['SampleNumber'].astype(str)\n",
        "samples['SampleNumber'] = samples['SampleNumber'].astype(str)\n",
        "\n",
        "#Merge the sample location dataframe to the analysis dataframe\n",
        "rockeval = rockeval.merge(samples,how='left',on=['OrderID','SampleNumber','Matrix'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu5xsc92JI9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rockeval.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty8HSlZYJI9K",
        "colab_type": "text"
      },
      "source": [
        "Notice that Comments columns with the '_x' and '_y'? This occurs when there are the same column name in both the two dataframes in the merge.\n",
        "\n",
        "Let's check those calculated values and set them to the surface elevation if they are null."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FRUcSYiJI9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(rockeval[rockeval['TVDSS_top'].isnull()].shape)\n",
        "rockeval['Z'] = rockeval['TVDSS_top'].where(rockeval['TVDSS_top'].notnull(),other=rockeval['ELEVF'])\n",
        "rockeval['Result'] = rockeval['Result'][rockeval['Result']!='ND']\n",
        "\n",
        "#Save out a copy for later\n",
        "#rockeval.to_csv('data/Rock-Eval.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o69WNkuhJI9M",
        "colab_type": "text"
      },
      "source": [
        "Let's take a portion of the pyrolysis data and look at maturity trends in North Dakota."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN5nXph2JI9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Filter to TMAX data in North Dakota\n",
        "nd = rockeval[rockeval['STATE']=='North Dakota'][rockeval['Param']=='TMAX']\n",
        "nullvals = ['ND','NA']\n",
        "nd = nd[~nd.Result.isin(nullvals)] # \"~\" means the opposite\n",
        "nd['Result'] = nd['Result'].astype(float)\n",
        "\n",
        "#Make a figure with matplotlib\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d') #nrows, ncols, and index\n",
        "\n",
        "#make a list our maturity cutoffs, colors, and labels.\n",
        "maturity = [(0,430,'saddlebrown','Immature'),\n",
        "    (435,445,'lime','Early'),\n",
        "    (445,450,'green','Peak'),\n",
        "    (450,470,'darkolivegreen','Late'),\n",
        "    (470,999, 'r','Gas')]\n",
        "\n",
        "#Populate the figure with a for loop\n",
        "for low,high,c,label in maturity:\n",
        "    xs = nd['Longitude'][(nd['Result']>=low)&(nd['Result']<high)]\n",
        "    ys = nd['Latitude'][(nd['Result']>=low)&(nd['Result']<high)]\n",
        "    zs = nd['Z'][(nd['Result']>=low)&(nd['Result']<high)]\n",
        "    ax.scatter(xs, ys, zs, c=c, marker='o')\n",
        "\n",
        "#Set the legend\n",
        "ax.legend([x[3] for x in maturity])\n",
        "\n",
        "#Rotate the figure\n",
        "ax.view_init(45,260)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyur0tE9JI9N",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Give it a try\n",
        "\n",
        "Try to reload the already merged rock-eval data, filter to the TOC data, preview your data, describe your data, and make a plot.  I've given you the framework for a scatterplot below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF6F0kEzJI9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Filter down to TOC analysis\n",
        "\n",
        "#Use \".describe()\" to find out about your resuls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAItTccJI9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make a scater plot with your results\n",
        "plt.scatter(toc['Longitude'], toc['Latitude'], c=toc['Result'])\n",
        "plt.gray()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}